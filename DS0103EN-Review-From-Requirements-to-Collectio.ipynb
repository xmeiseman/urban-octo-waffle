{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "f2725884697e323c3692ad6ea7e86fde8176f814337b5b05efd2753c4e19fcbb"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/IDSNlogo.png\" width=\"400\">\n\n# From Requirements to Collection\n\n\nEstimated time needed: **15** minutes\n    \n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n* Understand Data Requirements\n* Explore the stages in Data Collection\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    \n1. [Data Requirements](#0)<br>\n2. [Data Collection](#2)<br>\n</div>\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Data Requirements <a id=\"0\"></a>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig1_flowchart_data_requirements.png\" width=\"500\">\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In the videos, we learned that the chosen analytic approach determines the data requirements. Specifically, the analytic methods to be used require certain data content, formats and representations, guided by domain knowledge.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In the **From Problem to Approach Lab**, we determined that automating the process of determining the cuisine of a given recipe or dish is potentially possible using the ingredients of the recipe or the dish. In order to build a model, we need extensive data of different cuisines and recipes.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Identifying the required data fulfills the data requirements stage of the data science methodology.\n\n-----------\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Data Collection <a id=\"2\"></a>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig2_flowchart_data_collection.png\" width=\"500\">\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In the initial data collection stage, data scientists identify and gather the available data resources. These can be in the form of structured, unstructured, and even semi-structured data relevant to the problem domain.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Web Scraping of Online Food Recipes \n\nA researcher named Yong-Yeol Ahn scraped tens of thousands of food recipes (cuisines and ingredients) from three different websites, namely:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig3_allrecipes.png\" width=\"500\">\n<div align=\"center\">\nwww.allrecipes.com\n</div>\n<br/><br/>\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig4_epicurious.png\" width=\"500\">\n<div align=\"center\">\nwww.epicurious.com\n</div>\n<br/><br/>\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/images/lab2_fig5_menupan.png\" width=\"500\">\n<div align=\"center\">\nwww.menupan.com\n</div>\n<br/><br/>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For more information on Yong-Yeol Ahn and his research, you can read his paper on [Flavor Network and the Principles of Food Pairing](http://yongyeol.com/papers/ahn-flavornet-2011.pdf).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Luckily, we will not need to carry out any data collection as the data that we need to meet the goal defined in the business understanding stage is readily available.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### We have already acquired the data and placed it on an IBM server. Let's download the data and take a look at it.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Using this notebook:\n\nTo run any of the following cells of code, you can type **Shift + Enter** to excute the code in a cell.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n \nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n \npath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv\"\n \n#you will need to download the dataset; if you are running locally, please comment out the following \nawait download(path, \"recipes.csv\")\n \n \n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd # download library to read data into dataframe\npd.set_option('display.max_columns', None)\n\nrecipes = pd.read_csv(\"recipes.csv\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Read the data from the IBM server into a *pandas* dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Show the first few rows.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "recipes.head()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Get the dimensions of the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "recipes.shape",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So our dataset consists of 57,691 recipes. Each row represents a recipe, and for each recipe, the corresponding cuisine is documented as well as whether 384 ingredients exist in the recipe or not beginning with almond and ending with zucchini.\n\n-----------\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now that the data collection stage is complete, data scientists typically use descriptive statistics and visualization techniques to better understand the data and get acquainted with it. Data scientists, essentially, explore the data to:\n\n* understand its content,\n* assess its quality,\n* discover any interesting preliminary insights, and,\n* determine whether additional data is necessary to fill any gaps in the data.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Thank you for completing this lab!\n\n## Author\n\n<a href=\"https://www.linkedin.com/in/aklson/\" target=\"_blank\">Alex Aklson</a>\n\n<!--\n\n## Change Log\n\n\n|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n|---|---|---|---|\n| 2021-04-06 | 2.1 | Malika | Updated lab link |\n| 2020-09-25  | 2.0  | Lakshmi |  Fixed Typo errors |\n| 2020-08-27  | 2.0  | Lavanya  |  Moved lab to course repo in GitLab |\n\n-->\n\n<hr>\n\n## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n",
      "metadata": {}
    }
  ]
}